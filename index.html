<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=800">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
        /* Color scheme stolen from Sergey Karayev */
        a {
            color: #1772d0;
            text-decoration: none;
        }

        a:focus, a:hover {
            color: #f09228;
            text-decoration: none;
        }

        body, td, th, tr, p, a {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px
        }

        .hp-photo {
            width: 240px;
            height: 240px;
            border-radius: 240px;
            -webkit-border-radius: 240px;
            -moz-border-radius: 240px;
        }

        strong {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px;
        }

        heading {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 24px;
        }

        papertitle {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 15px;
            font-weight: 700
        }

        name {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 32px;
        }

        .one {
            width: 160px;
            height: 160px;
            position: relative;
        }

        .two {
            width: 160px;
            height: 160px;
            position: absolute;
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }

        .fade {
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }

        span.highlight {
            background-color: #ffffd0;
        }
    </style>

    <title>Guangchi Fang's Homepage</title>
    <link rel="icon" type="image/jpg" href="./imgs/icon.jpg">
</head>

<body>
<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody>
    <tr>
        <td>


            <!--SECTION 1 -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="68%" valign="middle">
                        <p align="center">
                            <name>Guangchi Fang 方广驰</name>
                        </p>
                        <p align="justify"> Hey, I'm Guangchi, a passionate explorer of 3D vision research.  
                            I just received my master's degree from Sun Yat-sen University, 
                            with Prof. Yulan Guo.
                            Previously, I obtained my B.Eng degree from 
                            University of Electronic Science and Technology of China.


                            <!--                    </br></br>-->
                            <!--                    In this summer (July - Oct 2019), I was a research intern at the Augumented Reality team of <a href="http://www.a9.com/">Amazon</a> (Palo Alto, CA).-->
                            <!--                    In my M.Phil study, I interned at <a href="https://www.astri.org/">Hong Kong Applied Science and Technology Research Institute</a>.-->
                            <!--                    In my undergraduate study, I was an exchange student at <a href="http://www.upv.es/">Universitat Politècnica de València</a> (Valencia, Spain).-->

                            </br>
                        </p>
                        <p align="center">
                            <a href="mailto:guangchi.fang@gmail.com">Email</a> /
                            <a href="https://github.com/fatPeter"> Github </a> /
                            <a href="https://scholar.google.com/citations?user=Jc1P0bcAAAAJ&hl=zh-CN">Google Scholar</a> /
                            <a href="https://www.youtube.com/channel/UCaN36zlgHCvamlefa9mX8vg"> YouTube </a>

                            <!-- 
                            <a href="https://twitter.com/guangchi_fang"> Twitter </a> /
                            <a href="https://www.youtube.com/channel/UCaN36zlgHCvamlefa9mX8vg"> YouTube </a>
                            -->

                            <!-- 
                            <a href="https://www.zhihu.com/people/hu-qing-yong"> Blog </a> /
                            <a href="https://www.linkedin.com/in/qingyong-hu-b18061171/"> LinkedIn </a> /
                            <a href="https://twitter.com/home"> Twitter </a> /
                            <a href="https://scholar.google.com/citations?user=yboFNHEAAAAJ&hl=en">Google Scholar</a>
                            -->


                        </p>
                    </td>
                    <td align="right"><img src="./imgs/selfie1.png" 
                    onmouseover="this.src='./imgs/selfie2.png'"
                    onmouseout="this.src='./imgs/selfie1.png'"
                    style="width: 135;"/></td>

                    <!-- <td align="right"><img class="hp-photo" src="./imgs/selfie.png" style="width: 240;"></td> -->
                </tr>
                </tbody>
            </table>

            <!--SECTION 2 -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <heading>Research</heading>
                        <p align="justify">

                            I am interested in 3D vision and deep learning. Currently, I focus on 3D data processing, 
                            typically for point cloud and neural representation.
                            
                            
                            
                            <!-- This is an interesting topic which enables 3D appliciations, such as AR/VR and autonomous 
                            driving. For more details, refer to <a href="https://mpeg-pcc.org/"> the ongoing standard</a> and 
                            <a href="https://arxiv.org/abs/2203.09931/">our work</a>. -->


                            <!-- I am interested in 3D computer vision, machine learning, and robotics. My research goal is
                            to build intelligent systems which are able to achieve an effective and efficient perception
                            and understanding of 3D scenes. In particular, my research focuses on large-scale point
                            cloud segmentation, dynamic point cloud processing, point cloud tracking, and local surface
                            matching. If you are interested in my research or have any use cases that you want to share,
                            feel free to <a href="mailto:qingyong.hu@cs.ox.ac.uk">contact me</a>! -->
                            <!--</br></br>-->
                            <!--<span class="highlight"><strong>Internship Position: </strong> If you're interested in ...</span> -->
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>

            
            <!--SECTION 3 -->
            <!--
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <heading>News</heading>
                        <p><strong>[2022.03.27]</strong> Our <a href="https://link.springer.com/article/10.1007/s11263-022-01632-6">3DPointCaps++</a> has been accepted to IJCV 2022!
                        <p><strong>[2022.03.02]</strong> Our <a href="https://arxiv.org/abs/2203.09931">3DAC</a> has been accepted to CVPR 2022!
                    </td>
                </tr>
                </tbody>
            </table>
            -->
            
            <!--SECTION 4 -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <heading>Publications</heading>
                    </td>
                </tr>
                </tbody>
            </table>


            <!--SECTION 5 -->
            

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/3DAC/3DAC.png" alt="PontTuset" width="180"
                                         style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/abs/2203.09931">
                            <papertitle>3DAC: Learning Attribute Compression for Point Clouds
                            </papertitle>
                        </a>
                            <br><strong>G. Fang</strong>, Q. Hu, H. Wang, Y. Xu, Y. Guo<br>
                            <em>CVPR 2022 </em><br>
                            <a href="https://arxiv.org/abs/2203.09931">Paper</a> /
                            <a href="https://github.com/fatPeter/ThreeDAC"><font >Code</font></a> /
                            <a href="https://www.youtube.com/watch?v=QTkkI0AyvLM&t=205s">Presentation</a> /
                            <a href="imgs/3DAC/3DAC_cvpr_poster.pdf">Poster</a>

                        <p align="justify" style="font-size:13px">We study the problem of attribute compression for large-scale unstructured 3D point clouds. Through an in-depth exploration of the relationships between different encoding steps and different attribute channels, we introduce a deep compression network, termed 3DAC, to explicitly compress the attributes of 3D point clouds and reduce storage usage in this paper.</p>
                        <p></p>
                    </td>
                </tr>
            </table>



            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/3DPointCaps.png" alt="PontTuset" width="180"
                                         style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://link.springer.com/article/10.1007/s11263-022-01632-6">
                            <papertitle>3DPointCaps++: Learning 3D Representations with Capsule Networks
                            </papertitle>
                        </a>
                            <br>Y. Zhao, <strong>G. Fang*</strong>, Y. Guo, L. Guibas, F. Tombari, T. Birdal<br>
                            <em>IJCV 2022 </em> (* indicates equal contribution) <br>
                            <a href="https://link.springer.com/article/10.1007/s11263-022-01632-6">Paper</a> /
                            <a href="https://github.com/yongheng1991/3D-point-capsule-networks/tree/plus"><font >Code</font></a> /
                            <a href="https://www.youtube.com/watch?v=04_Be2v6vYI"><font >Demo</font></a> 

                            
                            
                        <p align="justify" style="font-size:13px"> 
                            We present 3DPointCaps++ for learning robust, flexible and generalizable 3D object representations. Our algorithm builds a structured latent space with a 3D capsule encoder and learns a novel decoder on the individual latent sub-spaces with a cluster loss. Our network is able to tackle the challenging tasks of part segmentation, part interpolation/replacement as well as correspondence estimation across rigid / non-rigid shape, and across / within category. 
                        <p></p>
                    </td>
                </tr>
            </table>
                
    



            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/SQN_2.gif" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/abs/2104.04891">
                            <papertitle>SQN: Weakly-Supervised Semantic Segmentation of Large-Scale 3D Point Clouds
                            </papertitle>
                        </a>
                            <br>Q. Hu, B. Yang, <strong>G. Fang</strong>, A. Leornadis, Y. Guo, N. Trigoni, A.
                            Markham<br>
                            <em> ECCV 2022</em>
                            <br>
                            <!--<font color="red"><strong>..</strong></font><br>-->
                            <a href="https://arxiv.org/abs/2104.04891">ArXiv</a> / 
                            <a href="https://github.com/QingyongHu/SQN"><font >Code</font></a> /
                            <a href="https://www.youtube.com/watch?v=Q6wICSRRw3s&t=4s">Demo</a> /
                            <a href="https://www.youtube.com/watch?v=N0UAeY31msY&t=4s">Annotation</a>

                            <!--<iframe src="https://ghbtns.com/github-btn.html?user=QingyongHu&repo=SQN&type=star&count=true&size=small"
                                    frameborder="0" scrolling="0" width="120px" height="20px"></iframe>-->
                        <p align="justify" style="font-size:13px"> We propose a new weak supervision method to
                            implicitly augment the total amount of available supervision signals, by leveraging the
                            semantic similarity between neighboring points. Extensive experiments demonstrate that
                            the proposed Semantic Query Net- work (SQN) achieves state-of-the-art performance on six large-scale open datasets under weak supervision schemes, while requiring only 1‰ labeled points for training.</p>
                        <p></p>
                    </td>
                </tr>
            </table>


            <!--SECTION 6 -->

            <!--
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <heading>Individual Project</heading>
                    </td>
                </tr>
                </tbody>
            </table>




            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/project/urban_rec/demo.gif" alt="PontTuset" width="180"
                                         style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p>
                            <papertitle>Lidar-based Urban Scene Reconstruction</papertitle><br>
                            <a href="https://www.youtube.com/watch?v=-wwTcr_4UVE&t=4s">Presentation</a><br>
                        <p align="justify" style="font-size:13px">Lidar-based Urban Scene Reconstruction. A simple pipeline includes plane segmentation and multi-frame point clouds registration.</p>
                        <p></p>
                    </td>
                </tr>
            </table>


            

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/project/seed_filling/demo.gif" alt="PontTuset" width="180"
                                         style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p>
                            <papertitle>Tracking with Seed Filling
                            </papertitle>
                        </a><br>
                            <a href="https://github.com/fatPeter/Misc/tree/main/projects/Tracking_with_Seed_Filling"><font >Code</font></a> /
                            <a href="https://www.youtube.com/watch?v=rGaUNnhVKno">Demo</a>
                        <p align="justify" style="font-size:13px">Tracking with seed filling on a laptop. The center and the orientation of 2D objects are marked.</p>
                        <p></p>
                    </td>
                </tr>
            </table>
            
            -->


            


               

                <!--SECTION 6 -->
                
                <!--
                <table width="100%" align="center" border="0" cellspacing="0"
                       cellpadding="20">
                    <tbody>
                    <tr>
                        <td>
                            <heading>Teaching</heading>
                            <p><strong>Fall, 2020</strong>: &ensp;&ensp; 
                                    C programming
                            </a> (Sun Yat-sen University). </p>

                        </td>
                    </tr>
                    </tbody>
                </table>
                -->

                <!--

                <table width="100%" align="center" border="0" cellspacing="0"
                       cellpadding="20">
                    <tr>
                        <td width="100%" valign="middle">
                            <heading>Reviewer Services</heading>
                            <ul style="list-style-type:disc;">
                                <li>
                                    <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">
                                        IEEE Transactions on Pattern Analysis and Machine
                                        Intelligence (IEEE TPAMI)
                                <li>
                                    <a href="https://www.springer.com/journal/11263">
                                        International Journal of Computer Vision (IJCV)
                                <li>
                                    <a href="https://iclr.cc/">
                                        International Conference on Learning Representations
                                        (ICLR)
                                <li>
                                    <a href="https://icml.cc/">
                                        International Conference on Machine Learning
                                        (ICML)
                                <li>
                                    <a href="https://nips.cc/">
                                        Conference on Neural Information Processing Systems
                                        (NeurIPS)
                                <li>
                                    <a href="http://cvpr2021.thecvf.com/">
                                        IEEE Conference on Computer Vision and Pattern
                                        Recognition (CVPR)
                                <li>
                                    <a href="http://iccv2021.thecvf.com/home">
                                        International Conference on Computer Vision (ICCV)
                                <li>
                                    <a href="http://iccv2021.thecvf.com/home">
                                        European Conference on Computer Vision (ECCV)
                                <li>
                                    <a href="http://www.icra2021.org/">
                                        International Conference on Robotics and
                                        Automation (ICRA)
                                <li>
                                    <a href="http://www.ieee-ras.org/conferences-workshops/financially-co-sponsored/iros">
                                        IEEE/RSJ International Conference on Intelligent
                                        Robots
                                        and Systems (IROS)
                                <li><a href="https://bmvc2020.github.io/"> British
                                    Machine Vision Conference (BMVC)
                                <li>
                                    <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">
                                        IEEE Transactions on Image Processing (IEEE TIP)
                                <li>
                                    <a href="https://www.sciencedirect.com/journal/information-fusion">
                                        IEEE Transactions on Circuits and Systems for Video
                                        Technology (IEEE TCSVT)
                                <li>
                                    <a href="https://www.journals.elsevier.com/computers-and-graphics">
                                        Computers & Graphics (C&G)
                                <li>
                                    <a href="https://www.sciencedirect.com/journal/information-fusion">
                                        Information Fusion
                            </ul>
                        </td>
                    </tr>
                </table>

                -->





                <!--SECTION 9 -->
                <!--
                <div style="clear:both;">
                    <p align="right"><font size="2">
                        <script type="text/javascript" id="clustrmaps" 
                        src="//clustrmaps.com/map_v2.js?d=ru3r-7vObvqOxw9wm0ysc1pDpDmMgD88xA_cBZbJX_0&cl=ffffff&w=a"></script>
                    
                        
                    </font></p>
                    <br/>
                </div>
                -->

                <!--SECTION 10 -->
                <table width="100%" align="center" border="0" cellspacing="0"
                       cellpadding="20">
                    <tbody>
                    <tr>
                        <td><br>
                            <!--<p align="right"><font size="3">Erd&ouml;s = ? </font><br> -->
                            <p align="right"><font size="2"> <a
                                href="http://www.cs.berkeley.edu/~barron/">Thanks.</a></font>
                            </p>
                        </td>
                    </tr>
                    </tbody>
                </table>


                </td>
                </tr>
                </tbody>
            </table>
</body>
</html>
